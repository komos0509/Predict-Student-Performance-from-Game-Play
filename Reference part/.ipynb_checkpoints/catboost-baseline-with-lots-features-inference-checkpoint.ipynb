{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bb33cd",
   "metadata": {
    "papermill": {
     "duration": 0.007488,
     "end_time": "2023-03-07T07:50:58.656460",
     "exception": false,
     "start_time": "2023-03-07T07:50:58.648972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using Polars\n",
    "\n",
    "I learnt `polars` from last OTTO competition, which helped our team to do fast feature engineering when we faced `cudf`'s GPU memory errors.\n",
    "\n",
    "In this competition, although the data size is not as large as OTTO's, it is still convenient to use `polars` with cpu for easy train-inference adaption. Moreover, from my own experiment, the `polars` is faster than `pandas` in Kaggle's notebook even there is only 2-core CPU avalaible, which restricts the full strength of `polars` parallelism.\n",
    "\n",
    "And last, the current Kaggle environment (2023-02-17) has `polars` supported! You can save about 40s from installing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48057e4f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-07T07:50:58.666575Z",
     "iopub.status.busy": "2023-03-07T07:50:58.665791Z",
     "iopub.status.idle": "2023-03-07T07:51:00.458353Z",
     "shell.execute_reply": "2023-03-07T07:51:00.457222Z"
    },
    "papermill": {
     "duration": 1.800887,
     "end_time": "2023-03-07T07:51:00.461153",
     "exception": false,
     "start_time": "2023-03-07T07:50:58.660266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "# 기존 사용하려던 feature에서 fqid_lists, event_name_feature, text_lists, room_lists, levels, level_groups 가 추가되어 엄청 많은 피처가 생성될 것이 예상됩니다.\n",
    "CATS = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMS = ['page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "        'hover_duration', 'elapsed_time_diff']\n",
    "fqid_lists = ['worker', 'archivist', 'gramps', 'wells', 'toentry', 'confrontation', 'crane_ranger', 'groupconvo', 'flag_girl', 'tomap', 'tostacks', 'tobasement', 'archivist_glasses', 'boss', 'journals', 'seescratches', 'groupconvo_flag', 'cs', 'teddy', 'expert', 'businesscards', 'ch3start', 'tunic.historicalsociety', 'tofrontdesk', 'savedteddy', 'plaque', 'glasses', 'tunic.drycleaner', 'reader_flag', 'tunic.library', 'tracks', 'tunic.capitol_2', 'trigger_scarf', 'reader', 'directory', 'tunic.capitol_1', 'journals.pic_0.next', 'unlockdoor', 'tunic', 'what_happened', 'tunic.kohlcenter', 'tunic.humanecology', 'colorbook', 'logbook', 'businesscards.card_0.next', 'journals.hub.topics', 'logbook.page.bingo', 'journals.pic_1.next', 'journals_flag', 'reader.paper0.next', 'tracks.hub.deer', 'reader_flag.paper0.next', 'trigger_coffee', 'wellsbadge', 'journals.pic_2.next', 'tomicrofiche', 'journals_flag.pic_0.bingo', 'plaque.face.date', 'notebook', 'tocloset_dirty', 'businesscards.card_bingo.bingo', 'businesscards.card_1.next', 'tunic.wildlife', 'tunic.hub.slip', 'tocage', 'journals.pic_2.bingo', 'tocollectionflag', 'tocollection', 'chap4_finale_c', 'chap2_finale_c', 'lockeddoor', 'journals_flag.hub.topics', 'tunic.capitol_0', 'reader_flag.paper2.bingo', 'photo', 'tunic.flaghouse', 'reader.paper1.next', 'directory.closeup.archivist', 'intro', 'businesscards.card_bingo.next', 'reader.paper2.bingo', 'retirement_letter', 'remove_cup', 'journals_flag.pic_0.next', 'magnify', 'coffee', 'key', 'togrampa', 'reader_flag.paper1.next', 'janitor', 'tohallway', 'chap1_finale', 'report', 'outtolunch', 'journals_flag.hub.topics_old', 'journals_flag.pic_1.next', 'reader.paper2.next', 'chap1_finale_c', 'reader_flag.paper2.next', 'door_block_talk', 'journals_flag.pic_1.bingo', 'journals_flag.pic_2.next', 'journals_flag.pic_2.bingo', 'block_magnify', 'reader.paper0.prev', 'block', 'reader_flag.paper0.prev', 'block_0', 'door_block_clean', 'reader.paper2.prev', 'reader.paper1.prev', 'doorblock', 'tocloset', 'reader_flag.paper2.prev', 'reader_flag.paper1.prev', 'block_tomap2', 'journals_flag.pic_0_old.next', 'journals_flag.pic_1_old.next', 'block_tocollection', 'block_nelson', 'journals_flag.pic_2_old.next', 'block_tomap1', 'block_badge', 'need_glasses', 'block_badge_2', 'fox', 'block_1']\n",
    "\n",
    "name_feature = ['basic', 'undefined', 'close', 'open', 'prev', 'next']\n",
    "event_name_feature = ['cutscene_click', 'person_click', 'navigate_click',\n",
    "       'observation_click', 'notification_click', 'object_click',\n",
    "       'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "       'notebook_click']\n",
    "text_lists = ['tunic.historicalsociety.cage.confrontation', 'tunic.wildlife.center.crane_ranger.crane', 'tunic.historicalsociety.frontdesk.archivist.newspaper', 'tunic.historicalsociety.entry.groupconvo', 'tunic.wildlife.center.wells.nodeer', 'tunic.historicalsociety.frontdesk.archivist.have_glass', 'tunic.drycleaner.frontdesk.worker.hub', 'tunic.historicalsociety.closet_dirty.gramps.news', 'tunic.humanecology.frontdesk.worker.intro', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation', 'tunic.historicalsociety.basement.seescratches', 'tunic.historicalsociety.collection.cs', 'tunic.flaghouse.entry.flag_girl.hello', 'tunic.historicalsociety.collection.gramps.found', 'tunic.historicalsociety.basement.ch3start', 'tunic.historicalsociety.entry.groupconvo_flag', 'tunic.library.frontdesk.worker.hello', 'tunic.library.frontdesk.worker.wells', 'tunic.historicalsociety.collection_flag.gramps.flag', 'tunic.historicalsociety.basement.savedteddy', 'tunic.library.frontdesk.worker.nelson', 'tunic.wildlife.center.expert.removed_cup', 'tunic.library.frontdesk.worker.flag', 'tunic.historicalsociety.frontdesk.archivist.hello', 'tunic.historicalsociety.closet.gramps.intro_0_cs_0', 'tunic.historicalsociety.entry.boss.flag', 'tunic.flaghouse.entry.flag_girl.symbol', 'tunic.historicalsociety.closet_dirty.trigger_scarf', 'tunic.drycleaner.frontdesk.worker.done', 'tunic.historicalsociety.closet_dirty.what_happened', 'tunic.wildlife.center.wells.animals', 'tunic.historicalsociety.closet.teddy.intro_0_cs_0', 'tunic.historicalsociety.cage.glasses.afterteddy', 'tunic.historicalsociety.cage.teddy.trapped', 'tunic.historicalsociety.cage.unlockdoor', 'tunic.historicalsociety.stacks.journals.pic_2.bingo', 'tunic.historicalsociety.entry.wells.flag', 'tunic.humanecology.frontdesk.worker.badger', 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo', 'tunic.historicalsociety.closet.intro', 'tunic.historicalsociety.closet.retirement_letter.hub', 'tunic.historicalsociety.entry.directory.closeup.archivist', 'tunic.historicalsociety.collection.tunic.slip', 'tunic.kohlcenter.halloffame.plaque.face.date', 'tunic.historicalsociety.closet_dirty.trigger_coffee', 'tunic.drycleaner.frontdesk.logbook.page.bingo', 'tunic.library.microfiche.reader.paper2.bingo', 'tunic.kohlcenter.halloffame.togrampa', 'tunic.capitol_2.hall.boss.haveyougotit', 'tunic.wildlife.center.wells.nodeer_recap', 'tunic.historicalsociety.cage.glasses.beforeteddy', 'tunic.historicalsociety.closet_dirty.gramps.helpclean', 'tunic.wildlife.center.expert.recap', 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap', 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo', 'tunic.historicalsociety.cage.lockeddoor', 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo', 'tunic.historicalsociety.collection.gramps.lost', 'tunic.historicalsociety.closet.notebook', 'tunic.historicalsociety.frontdesk.magnify', 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo', 'tunic.wildlife.center.remove_cup', 'tunic.library.frontdesk.wellsbadge.hub', 'tunic.wildlife.center.tracks.hub.deer', 'tunic.historicalsociety.frontdesk.key', 'tunic.library.microfiche.reader_flag.paper2.bingo', 'tunic.flaghouse.entry.colorbook', 'tunic.wildlife.center.coffee', 'tunic.capitol_1.hall.boss.haveyougotit', 'tunic.historicalsociety.basement.janitor', 'tunic.historicalsociety.collection_flag.gramps.recap', 'tunic.wildlife.center.wells.animals2', 'tunic.flaghouse.entry.flag_girl.symbol_recap', 'tunic.historicalsociety.closet_dirty.photo', 'tunic.historicalsociety.stacks.outtolunch', 'tunic.library.frontdesk.worker.wells_recap', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap', 'tunic.capitol_0.hall.boss.talktogramps', 'tunic.historicalsociety.closet.photo', 'tunic.historicalsociety.collection.tunic', 'tunic.historicalsociety.closet.teddy.intro_0_cs_5', 'tunic.historicalsociety.closet_dirty.gramps.archivist', 'tunic.historicalsociety.closet_dirty.door_block_talk', 'tunic.historicalsociety.entry.boss.flag_recap', 'tunic.historicalsociety.frontdesk.archivist.need_glass_0', 'tunic.historicalsociety.entry.wells.talktogramps', 'tunic.historicalsociety.frontdesk.block_magnify', 'tunic.historicalsociety.frontdesk.archivist.foundtheodora', 'tunic.historicalsociety.closet_dirty.gramps.nothing', 'tunic.historicalsociety.closet_dirty.door_block_clean', 'tunic.capitol_1.hall.boss.writeitup', 'tunic.library.frontdesk.worker.nelson_recap', 'tunic.library.frontdesk.worker.hello_short', 'tunic.historicalsociety.stacks.block', 'tunic.historicalsociety.frontdesk.archivist.need_glass_1', 'tunic.historicalsociety.entry.boss.talktogramps', 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap', 'tunic.historicalsociety.entry.wells.flag_recap', 'tunic.drycleaner.frontdesk.worker.done2', 'tunic.library.frontdesk.worker.flag_recap', 'tunic.humanecology.frontdesk.block_0', 'tunic.library.frontdesk.worker.preflag', 'tunic.historicalsociety.basement.gramps.seeyalater', 'tunic.flaghouse.entry.flag_girl.hello_recap', 'tunic.historicalsociety.closet.doorblock', 'tunic.drycleaner.frontdesk.worker.takealook', 'tunic.historicalsociety.basement.gramps.whatdo', 'tunic.library.frontdesk.worker.droppedbadge', 'tunic.historicalsociety.entry.block_tomap2', 'tunic.library.frontdesk.block_nelson', 'tunic.library.microfiche.block_0', 'tunic.historicalsociety.entry.block_tocollection', 'tunic.historicalsociety.entry.block_tomap1', 'tunic.historicalsociety.collection.gramps.look_0', 'tunic.library.frontdesk.block_badge', 'tunic.historicalsociety.cage.need_glasses', 'tunic.library.frontdesk.block_badge_2', 'tunic.kohlcenter.halloffame.block_0', 'tunic.capitol_0.hall.chap1_finale_c', 'tunic.capitol_1.hall.chap2_finale_c', 'tunic.capitol_2.hall.chap4_finale_c', 'tunic.wildlife.center.fox.concern', 'tunic.drycleaner.frontdesk.block_0', 'tunic.historicalsociety.entry.gramps.hub', 'tunic.humanecology.frontdesk.block_1', 'tunic.drycleaner.frontdesk.block_1']\n",
    "room_lists = ['tunic.historicalsociety.entry', 'tunic.wildlife.center', 'tunic.historicalsociety.cage', 'tunic.library.frontdesk', 'tunic.historicalsociety.frontdesk', 'tunic.historicalsociety.stacks', 'tunic.historicalsociety.closet_dirty', 'tunic.humanecology.frontdesk', 'tunic.historicalsociety.basement', 'tunic.kohlcenter.halloffame', 'tunic.library.microfiche', 'tunic.drycleaner.frontdesk', 'tunic.historicalsociety.collection', 'tunic.historicalsociety.closet', 'tunic.flaghouse.entry', 'tunic.historicalsociety.collection_flag', 'tunic.capitol_1.hall', 'tunic.capitol_0.hall', 'tunic.capitol_2.hall']\n",
    "\n",
    "LEVELS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "level_groups = [\"0-4\", \"5-12\", \"13-22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82f482a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:00.471018Z",
     "iopub.status.busy": "2023-03-07T07:51:00.470316Z",
     "iopub.status.idle": "2023-03-07T07:51:01.310428Z",
     "shell.execute_reply": "2023-03-07T07:51:01.309218Z"
    },
    "papermill": {
     "duration": 0.848172,
     "end_time": "2023-03-07T07:51:01.313087",
     "exception": false,
     "start_time": "2023-03-07T07:51:00.464915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    pl.col(\"page\").cast(pl.Float32),\n",
    "    (\n",
    "        (pl.col(\"elapsed_time\") - pl.col(\"elapsed_time\").shift(1))\n",
    "        .fill_null(0)\n",
    "        .clip(0, 1e9)\n",
    "        .over([\"session_id\", \"level\"])\n",
    "        .alias(\"elapsed_time_diff\")\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_x\") - pl.col(\"screen_coor_x\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_y\") - pl.col(\"screen_coor_y\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    pl.col(\"fqid\").fill_null(\"fqid_None\"),\n",
    "    pl.col(\"text_fqid\").fill_null(\"text_fqid_None\")\n",
    "\n",
    "]\n",
    "\n",
    "models_list = [[CatBoostClassifier().load_model(\n",
    "    f\"/kaggle/input/catboostbaseline-train/fold{fold}_q{q}.cbm\"\n",
    ") for fold in range(5)] for q in range(1, 19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15fbcd32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:01.322856Z",
     "iopub.status.busy": "2023-03-07T07:51:01.322004Z",
     "iopub.status.idle": "2023-03-07T07:51:01.376647Z",
     "shell.execute_reply": "2023-03-07T07:51:01.375632Z"
    },
    "papermill": {
     "duration": 0.062515,
     "end_time": "2023-03-07T07:51:01.379286",
     "exception": false,
     "start_time": "2023-03-07T07:51:01.316771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(x, grp, use_extra, feature_suffix):\n",
    "    aggs = [\n",
    "        pl.col(\"index\").count().alias(f\"session_number_{feature_suffix}\"),\n",
    "\n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") for c in CATS],\n",
    "\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).sum().alias(f\"{c}_sum_{feature_suffix}\") for c in NUMS],\n",
    "\n",
    "        *[pl.col(\"fqid\").filter(pl.col(\"fqid\") == c).count().alias(f\"{c}_fqid_counts{feature_suffix}\")\n",
    "          for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "\n",
    "\n",
    "        *[pl.col(\"text_fqid\").filter(pl.col(\"text_fqid\") == c).count().alias(f\"{c}_text_fqid_counts{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "\n",
    "        *[pl.col(\"room_fqid\").filter(pl.col(\"room_fqid\") == c).count().alias(f\"{c}_room_fqid_counts{feature_suffix}\")\n",
    "          for c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "\n",
    "        *[pl.col(\"event_name\").filter(pl.col(\"event_name\") == c).count().alias(f\"{c}_event_name_counts{feature_suffix}\")\n",
    "          for c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\")for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "\n",
    "        *[pl.col(\"name\").filter(pl.col(\"name\") == c).count().alias(f\"{c}_name_counts{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "\n",
    "        *[pl.col(\"level\").filter(pl.col(\"level\") == c).count().alias(f\"{c}_LEVEL_count{feature_suffix}\") for c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "\n",
    "        *[pl.col(\"level_group\").filter(pl.col(\"level_group\") == c).count().alias(f\"{c}_LEVEL_group_count{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "\n",
    "        *[pl.col(\"index\").filter((pl.col(\"level\") == c) & (pl.col('room_fqid') == d)).count().alias(f\"{c}{d}_level_room_count{feature_suffix}\") for c in LEVELS for d in room_lists],\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "\n",
    "    if use_extra:\n",
    "        if grp == '5-12':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter((pl.col(\"text\")==\"Here's the log book.\")\n",
    "                                              |(pl.col(\"fqid\")=='logbook.page.bingo'))\n",
    "                    .apply(lambda s: s.max()-s.min()).alias(\"logbook_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    (pl.col(\"text\") == \"Here's the log book.\") | (pl.col(\"fqid\") == 'logbook.page.bingo')).apply(\n",
    "                    lambda s: s.max() - s.min()).alias(\"logbook_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                                pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                            pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                                pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                            pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_indexCount\"),\n",
    "            ]\n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "        if grp == '13-22':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                                pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                                pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                                pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                                pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_indexCount\")\n",
    "            ]\n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "    return df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca2c4c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:01.389042Z",
     "iopub.status.busy": "2023-03-07T07:51:01.388064Z",
     "iopub.status.idle": "2023-03-07T07:51:01.397843Z",
     "shell.execute_reply": "2023-03-07T07:51:01.396946Z"
    },
    "papermill": {
     "duration": 0.017061,
     "end_time": "2023-03-07T07:51:01.400022",
     "exception": false,
     "start_time": "2023-03-07T07:51:01.382961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# date 피처 추가생성\n",
    "def time_feature(train):\n",
    "    train[\"year\"] = train[\"session_id\"].apply(lambda x: int(str(x)[:2])).astype(np.uint8)\n",
    "    train[\"month\"] = train[\"session_id\"].apply(lambda x: int(str(x)[2:4])+1).astype(np.uint8)\n",
    "    train[\"day\"] = train[\"session_id\"].apply(lambda x: int(str(x)[4:6])).astype(np.uint8)\n",
    "    train[\"hour\"] = train[\"session_id\"].apply(lambda x: int(str(x)[6:8])).astype(np.uint8)\n",
    "    train[\"minute\"] = train[\"session_id\"].apply(lambda x: int(str(x)[8:10])).astype(np.uint8)\n",
    "    train[\"second\"] = train[\"session_id\"].apply(lambda x: int(str(x)[10:12])).astype(np.uint8)\n",
    "\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8129db96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:01.409241Z",
     "iopub.status.busy": "2023-03-07T07:51:01.408601Z",
     "iopub.status.idle": "2023-03-07T07:51:01.430239Z",
     "shell.execute_reply": "2023-03-07T07:51:01.429175Z"
    },
    "papermill": {
     "duration": 0.029696,
     "end_time": "2023-03-07T07:51:01.433364",
     "exception": false,
     "start_time": "2023-03-07T07:51:01.403668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd550c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:01.442131Z",
     "iopub.status.busy": "2023-03-07T07:51:01.441692Z",
     "iopub.status.idle": "2023-03-07T07:51:01.452825Z",
     "shell.execute_reply": "2023-03-07T07:51:01.451628Z"
    },
    "papermill": {
     "duration": 0.018374,
     "end_time": "2023-03-07T07:51:01.455335",
     "exception": false,
     "start_time": "2023-03-07T07:51:01.436961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_read = open('/kaggle/input/catboostbaseline-train/importance_dict.pkl', 'rb')\n",
    "importance_dict = pickle.load(f_read)\n",
    "f_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abd3316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:01.464732Z",
     "iopub.status.busy": "2023-03-07T07:51:01.463754Z",
     "iopub.status.idle": "2023-03-07T07:51:07.210016Z",
     "shell.execute_reply": "2023-03-07T07:51:07.208629Z"
    },
    "papermill": {
     "duration": 5.753427,
     "end_time": "2023-03-07T07:51:07.212430",
     "exception": false,
     "start_time": "2023-03-07T07:51:01.459003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "for (sample_submission, test) in iter_test:\n",
    "    grp = test.level_group.values[0]\n",
    "    session_id = test.session_id.values[0]\n",
    "\n",
    "    \n",
    "    df = (pl.from_pandas(test)\n",
    "          .drop([\"fullscreen\", \"hq\", \"music\"])\n",
    "          .with_columns(columns))\n",
    "    df = feature_engineer(df, grp, use_extra=True, feature_suffix='')\n",
    "    df = time_feature(df)\n",
    "    \n",
    "    fold = 0\n",
    "    preds = []\n",
    "    a,b = limits[grp]\n",
    "    for q in range(a, b):\n",
    "        print(q)\n",
    "        FEATURES = importance_dict[str(q)]\n",
    "        model = models_list[q-1][fold]\n",
    "        \n",
    "        pred = model.predict_proba(df[FEATURES].astype(np.float32))[0,1]\n",
    "        preds.append(int(pred > 0.63))\n",
    "\n",
    "    sample_submission[\"correct\"] = preds\n",
    "\n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b55875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T07:51:07.224613Z",
     "iopub.status.busy": "2023-03-07T07:51:07.223575Z",
     "iopub.status.idle": "2023-03-07T07:51:07.243031Z",
     "shell.execute_reply": "2023-03-07T07:51:07.242030Z"
    },
    "papermill": {
     "duration": 0.030061,
     "end_time": "2023-03-07T07:51:07.247547",
     "exception": false,
     "start_time": "2023-03-07T07:51:07.217486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 2) 0.5925925925925926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090109393214576_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090109393214576_q2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090109393214576_q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312143683264_q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312143683264_q2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090109393214576_q1        1\n",
       "1  20090109393214576_q2        1\n",
       "2  20090109393214576_q3        1\n",
       "3  20090312143683264_q1        0\n",
       "4  20090312143683264_q2        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub.shape, sub.correct.mean())\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.305608,
   "end_time": "2023-03-07T07:51:08.077900",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-07T07:50:47.772292",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
